// ASRStreamService.swift - å®æ—¶æµå¼è¯­éŸ³è¯†åˆ«æœåŠ¡
// ä½¿ç”¨ WebSocket è¿æ¥åç«¯ï¼Œå®ç°è¾¹è¯´è¾¹è¯†åˆ«

import AVFoundation
import Combine
import Foundation

class ASRStreamService: NSObject, ObservableObject {
    @Published var transcript = ""
    @Published var isRecording = false
    @Published var isConnected = false
    @Published var error: String?
    @Published var audioLevel: Float = 0.0  // éŸ³é¢‘éŸ³é‡çº§åˆ« (0.0-1.0)
    @Published var isDetectingAudio = false  // æ˜¯å¦æ£€æµ‹åˆ°éŸ³é¢‘
    @Published var statusMessage: String?  // çŠ¶æ€æç¤ºæ¶ˆæ¯

    private var webSocketTask: URLSessionWebSocketTask?
    private let audioEngine = AVAudioEngine()
    private var audioFormat: AVAudioFormat?

    private var onTranscriptUpdate: ((String, Bool) -> Void)?
    private var onDeepgramReady: (() -> Void)?
    private var heartbeatTimer: Timer?
    private var reconnectTimer: Timer?
    private var shouldAutoReconnect = true  // æ˜¯å¦è‡ªåŠ¨é‡è¿
    private var reconnectAttempts = 0
    private var lastTranscriptTime: Date?  // æœ€åæ”¶åˆ°è¯†åˆ«ç»“æœçš„æ—¶é—´
    private var noAudioTimer: Timer?  // æ— éŸ³é¢‘æ£€æµ‹è®¡æ—¶å™¨
    private var deepgramConnectionTime: Date?  // Deepgram è¿æ¥æ—¶é—´

    override init() {
        super.init()
    }

    deinit {
        heartbeatTimer?.invalidate()
        reconnectTimer?.invalidate()
        noAudioTimer?.invalidate()
        shouldAutoReconnect = false
    }

    // MARK: - WebSocket è¿æ¥

    @MainActor
    func connect(language: String = "zh-CN", model: String = "nova-2") async {
        // æ„å»º WebSocket URL
        var wsURL = AppConfig.apiBaseURL
            .replacingOccurrences(of: "http://", with: "ws://")
            .replacingOccurrences(of: "https://", with: "wss://")

        // ç§»é™¤è·¯å¾„éƒ¨åˆ†ï¼Œåªä¿ç•™ host:port
        if let urlComponents = URLComponents(string: wsURL) {
            var components = urlComponents
            components.path = ""
            components.port = 9525  // ASR WebSocket ç«¯å£
            wsURL = components.string ?? wsURL
        }

        Logger.info("åŸå§‹ API URL: \(AppConfig.apiBaseURL)")
        Logger.info("WebSocket URL: \(wsURL)")

        guard let url = URL(string: wsURL) else {
            self.error = "æ— æ•ˆçš„ WebSocket URL"
            Logger.error("æ— æ•ˆçš„ WebSocket URL: \(wsURL)")
            return
        }

        // åˆ›å»º WebSocket è¿æ¥
        let session = URLSession(configuration: .default)
        webSocketTask = session.webSocketTask(with: url)
        webSocketTask?.resume()

        isConnected = true

        // å¼€å§‹æ¥æ”¶æ¶ˆæ¯
        receiveMessage()

        // å¯åŠ¨å¿ƒè·³ä¿æŒè¿æ¥
        startHeartbeat()

        Logger.info("WebSocket è¿æ¥æˆåŠŸï¼Œå¿ƒè·³å·²å¯åŠ¨")
    }

    @MainActor
    func disconnect() async {
        guard isConnected else { return }

        // å‘é€åœæ­¢æ¶ˆæ¯
        let stopMessage: [String: Any] = ["type": "stop"]
        await sendMessage(stopMessage)

        // å…³é—­è¿æ¥
        webSocketTask?.cancel(with: .goingAway, reason: nil)
        webSocketTask = nil
        isConnected = false

        Logger.info("WebSocket è¿æ¥å·²å…³é—­")
    }

    // MARK: - æ¶ˆæ¯å¤„ç†

    private func receiveMessage() {
        webSocketTask?.receive { [weak self] result in
            guard let self = self else { return }

            switch result {
            case .success(let message):
                switch message {
                case .string(let text):
                    self.handleTextMessage(text)
                case .data:
                    // ä¸å¤„ç†äºŒè¿›åˆ¶æ¶ˆæ¯
                    break
                @unknown default:
                    break
                }

                // ç»§ç»­æ¥æ”¶ä¸‹ä¸€æ¡æ¶ˆæ¯
                self.receiveMessage()

            case .failure(let error):
                Logger.error("ASR WebSocket Error: \(error.localizedDescription)")
                Task { @MainActor in
                    self.error = error.localizedDescription
                    self.isConnected = false

                    // è§¦å‘è‡ªåŠ¨é‡è¿
                    self.startAutoReconnect()
                }
            }
        }
    }

    private func handleTextMessage(_ text: String) {
        guard let data = text.data(using: .utf8),
            let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
            let type = json["type"] as? String
        else {
            return
        }

        Task { @MainActor in
            switch type {
            case "connected":
                Logger.info("WebSocket è¿æ¥æˆåŠŸ")
                
            case "connecting":
                let message = json["message"] as? String ?? "æ­£åœ¨è¿æ¥ Deepgram..."
                Logger.info("ğŸ“¡ \(message)")
                self.statusMessage = "ğŸ“¡ æ­£åœ¨è¿æ¥è¯­éŸ³è¯†åˆ«æœåŠ¡..."

            case "started":
                Logger.info("è¯†åˆ«å·²å¯åŠ¨ï¼ŒDeepgram å‡†å¤‡å°±ç»ª")
                self.deepgramConnectionTime = Date()
                self.statusMessage = "ğŸ¤ å¼€å§‹è¯´è¯..."
                
                // å¯åŠ¨æ— éŸ³é¢‘æ£€æµ‹è®¡æ—¶å™¨ï¼ˆ15ç§’åå¦‚æœæ²¡æœ‰è¯†åˆ«ç»“æœï¼Œç»™å‡ºæç¤ºï¼‰
                self.startNoAudioDetectionTimer()
                
                // é€šçŸ¥ Deepgram å·²å°±ç»ªï¼Œå¯ä»¥å¼€å§‹å½•éŸ³
                self.onDeepgramReady?()

            case "transcript":
                let transcript = json["transcript"] as? String ?? ""
                let isFinal = json["is_final"] as? Bool ?? false
                let confidence = json["confidence"] as? Double ?? 0

                Logger.info("è¯†åˆ«ç»“æœ: \(transcript) [isFinal: \(isFinal), confidence: \(confidence)]")

                // æ›´æ–°æœ€åè¯†åˆ«æ—¶é—´
                self.lastTranscriptTime = Date()
                
                // æ¸…é™¤çŠ¶æ€æ¶ˆæ¯
                self.statusMessage = nil
                
                // é‡ç½®æ— éŸ³é¢‘æ£€æµ‹è®¡æ—¶å™¨
                self.resetNoAudioDetectionTimer()

                // æ›´æ–°æ–‡æœ¬
                self.transcript = transcript

                // è°ƒç”¨å›è°ƒ
                self.onTranscriptUpdate?(transcript, isFinal)

            case "stopped":
                Logger.info("è¯†åˆ«å·²åœæ­¢")
                self.isRecording = false

            case "deepgram_closed":
                let message = json["message"] as? String
                Logger.info("Deepgram è¿æ¥å·²å…³é—­: \(message ?? "")")
                self.isRecording = false
                
                // å¦‚æœæ˜¯åœ¨å½•éŸ³è¿‡ç¨‹ä¸­æ–­å¼€ï¼ˆéä¸»åŠ¨åœæ­¢ï¼‰ï¼Œæ˜¾ç¤ºè­¦å‘Š
                if self.isRecording {
                    self.statusMessage = "âš ï¸ è¯­éŸ³è¯†åˆ«æœåŠ¡å·²æ–­å¼€ï¼Œè¯·é‡æ–°å¼€å§‹"
                } else {
                    // ä¸»åŠ¨åœæ­¢çš„æƒ…å†µï¼Œä¸æ˜¾ç¤ºé”™è¯¯
                    self.statusMessage = nil
                }
                
                self.stopNoAudioDetectionTimer()

            case "error":
                let errorMsg = json["message"] as? String ?? "Unknown error"
                let originalError = json["original_error"] as? String
                
                Logger.error("æœåŠ¡å™¨é”™è¯¯: \(errorMsg)")
                if let originalError = originalError {
                    Logger.error("åŸå§‹é”™è¯¯: \(originalError)")
                }
                
                self.error = errorMsg
                
                // æ ¹æ®é”™è¯¯ç±»å‹æ˜¾ç¤ºä¸åŒçš„çŠ¶æ€æ¶ˆæ¯
                if errorMsg.contains("API") || errorMsg.contains("è®¤è¯") {
                    self.statusMessage = "âŒ API é…ç½®é”™è¯¯ï¼Œè¯·è”ç³»ç®¡ç†å‘˜"
                } else if errorMsg.contains("ç½‘ç»œ") || errorMsg.contains("è¿æ¥") || errorMsg.contains("è¶…æ—¶") {
                    self.statusMessage = "âŒ ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ"
                } else if errorMsg.contains("DNS") {
                    self.statusMessage = "âŒ ç½‘ç»œé…ç½®é”™è¯¯"
                } else if errorMsg.contains("ä¸å¯ç”¨") || errorMsg.contains("503") {
                    self.statusMessage = "âŒ æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•"
                } else if errorMsg.contains("é¢‘ç‡") || errorMsg.contains("è¶…é™") {
                    self.statusMessage = "âŒ ä½¿ç”¨é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åå†è¯•"
                } else {
                    self.statusMessage = "âŒ \(errorMsg)"
                }
                
                self.stopNoAudioDetectionTimer()

            case "pong":
                // å¿ƒè·³å“åº”
                break

            default:
                Logger.info("æœªçŸ¥æ¶ˆæ¯ç±»å‹: \(type)")
            }
        }
    }

    private func sendMessage(_ message: [String: Any]) async {
        guard let data = try? JSONSerialization.data(withJSONObject: message),
            let text = String(data: data, encoding: .utf8)
        else {
            return
        }

        let message = URLSessionWebSocketTask.Message.string(text)

        do {
            try await webSocketTask?.send(message)
        } catch {
            Logger.error("å‘é€æ¶ˆæ¯å¤±è´¥: \(error.localizedDescription)")
        }
    }

    // MARK: - å½•éŸ³æ§åˆ¶

    @MainActor
    func startRecording(
        language: String = "zh-CN",
        model: String = "nova-2",
        onDeepgramReady: @escaping () -> Void,
        onTranscriptUpdate: @escaping (String, Bool) -> Void
    ) {
        // ä¿å­˜å›è°ƒï¼Œç­‰å¾… Deepgram å°±ç»ªåå†å¯åŠ¨éŸ³é¢‘å¼•æ“
        self.onDeepgramReady = { [weak self] in
            guard let self = self else { return }
            // Deepgram å°±ç»ªï¼Œå¯åŠ¨éŸ³é¢‘å¼•æ“
            Task { @MainActor in
                self.startAudioEngine()
                // è°ƒç”¨å¤–éƒ¨çš„å°±ç»ªå›è°ƒ
                onDeepgramReady()
            }
        }
        self.onTranscriptUpdate = onTranscriptUpdate

        guard isConnected else {
            self.error = "WebSocket æœªè¿æ¥"
            return
        }

        // å‘é€ start æ¶ˆæ¯ï¼Œè§¦å‘ Deepgram è¿æ¥
        Task {
            let startMessage: [String: Any] = [
                "type": "start",
                "language": language,
                "model": model,
            ]
            await sendMessage(startMessage)
            Logger.info("å·²å‘é€ start æ¶ˆæ¯ï¼Œç­‰å¾… Deepgram å°±ç»ª...")
        }
    }

    // å¯åŠ¨éŸ³é¢‘å¼•æ“ï¼ˆDeepgram å°±ç»ªåè°ƒç”¨ï¼‰
    @MainActor
    private func startAudioEngine() {
        // é…ç½®éŸ³é¢‘ä¼šè¯
        let audioSession = AVAudioSession.sharedInstance()
        do {
            try audioSession.setCategory(.record, mode: .measurement, options: .duckOthers)
            try audioSession.setActive(true)
        } catch {
            Logger.error("éŸ³é¢‘ä¼šè¯é…ç½®å¤±è´¥: \(error)")
            self.error = "éŸ³é¢‘ä¼šè¯é…ç½®å¤±è´¥"
            self.statusMessage = "âŒ éº¦å…‹é£é…ç½®å¤±è´¥"
            return
        }

        // é…ç½®éŸ³é¢‘æ ¼å¼ï¼š16kHz, å•å£°é“, 16-bit PCM
        let inputNode = audioEngine.inputNode
        let inputFormat = inputNode.outputFormat(forBus: 0)

        // åˆ›å»ºç›®æ ‡æ ¼å¼ï¼š16kHz, Int16, Interleavedï¼ˆDeepgram è¦æ±‚ï¼‰
        guard
            let targetFormat = AVAudioFormat(
                commonFormat: .pcmFormatInt16,
                sampleRate: 16000,
                channels: 1,
                interleaved: true  // âœ… Deepgram éœ€è¦äº¤é”™æ ¼å¼
            )
        else {
            self.error = "æ— æ³•åˆ›å»ºéŸ³é¢‘æ ¼å¼"
            self.statusMessage = "âŒ éŸ³é¢‘æ ¼å¼é”™è¯¯"
            return
        }

        self.audioFormat = targetFormat

        // åˆ›å»ºæ ¼å¼è½¬æ¢å™¨
        guard let converter = AVAudioConverter(from: inputFormat, to: targetFormat) else {
            self.error = "æ— æ³•åˆ›å»ºéŸ³é¢‘è½¬æ¢å™¨"
            self.statusMessage = "âŒ éŸ³é¢‘è½¬æ¢å™¨é”™è¯¯"
            return
        }

        // å®‰è£…éŸ³é¢‘é‡‡é›†
        inputNode.installTap(onBus: 0, bufferSize: 4096, format: inputFormat) { [weak self] buffer, _ in
            guard let self = self else { return }

            // è®¡ç®—éŸ³é¢‘éŸ³é‡çº§åˆ«
            self.calculateAudioLevel(buffer: buffer)
            
            // è½¬æ¢éŸ³é¢‘æ ¼å¼
            self.convertAndSendAudio(buffer: buffer, converter: converter, targetFormat: targetFormat)
        }

        // å¯åŠ¨éŸ³é¢‘å¼•æ“
        do {
            try audioEngine.start()
            isRecording = true
            Logger.info("âœ… éŸ³é¢‘å¼•æ“å·²å¯åŠ¨ï¼Œå¼€å§‹å½•éŸ³")
        } catch {
            Logger.error("éŸ³é¢‘å¼•æ“å¯åŠ¨å¤±è´¥: \(error)")
            self.error = "æ— æ³•å¯åŠ¨å½•éŸ³"
            self.statusMessage = "âŒ æ— æ³•å¯åŠ¨å½•éŸ³"
        }
    }

    @MainActor
    func stopRecording() {
        guard isRecording else {
            Logger.debug("å½•éŸ³æœªåœ¨è¿›è¡Œä¸­ï¼Œå¿½ç•¥åœæ­¢è¯·æ±‚")
            return
        }

        // åœæ­¢éŸ³é¢‘å¼•æ“
        if audioEngine.isRunning {
            audioEngine.stop()
            audioEngine.inputNode.removeTap(onBus: 0)
        }

        isRecording = false
        audioLevel = 0.0
        isDetectingAudio = false
        statusMessage = nil
        
        // åœæ­¢æ— éŸ³é¢‘æ£€æµ‹è®¡æ—¶å™¨
        stopNoAudioDetectionTimer()

        // å‘é€ stop æ¶ˆæ¯ï¼Œè®©æœåŠ¡å™¨æ–­å¼€ Deepgram
        Task {
            let stopMessage: [String: Any] = ["type": "stop"]
            await sendMessage(stopMessage)
            Logger.info("åœæ­¢å½•éŸ³ï¼Œå·²å‘é€ stop æ¶ˆæ¯")
        }
    }

    // MARK: - éŸ³é¢‘éŸ³é‡æ£€æµ‹
    
    private func calculateAudioLevel(buffer: AVAudioPCMBuffer) {
        guard let channelData = buffer.floatChannelData?[0] else { return }
        
        let frameLength = Int(buffer.frameLength)
        var sum: Float = 0.0
        
        // è®¡ç®— RMSï¼ˆå‡æ–¹æ ¹ï¼‰
        for i in 0..<frameLength {
            let sample = channelData[i]
            sum += sample * sample
        }
        
        let rms = sqrt(sum / Float(frameLength))
        let db = 20 * log10(rms)
        
        // å½’ä¸€åŒ–åˆ° 0-1 èŒƒå›´ï¼ˆ-60dB åˆ° 0dBï¼‰
        let normalizedLevel = max(0, min(1, (db + 60) / 60))
        
        Task { @MainActor in
            self.audioLevel = normalizedLevel
            
            // æ£€æµ‹æ˜¯å¦æœ‰å£°éŸ³ï¼ˆé˜ˆå€¼ 0.1ï¼‰
            let hasAudio = normalizedLevel > 0.1
            if hasAudio != self.isDetectingAudio {
                self.isDetectingAudio = hasAudio
                if hasAudio {
                    Logger.debug("ğŸ¤ æ£€æµ‹åˆ°å£°éŸ³ï¼ŒéŸ³é‡: \(normalizedLevel)")
                }
            }
        }
    }
    
    // MARK: - æ— éŸ³é¢‘æ£€æµ‹è®¡æ—¶å™¨
    
    private func startNoAudioDetectionTimer() {
        stopNoAudioDetectionTimer()
        
        noAudioTimer = Timer.scheduledTimer(withTimeInterval: 5.0, repeats: true) { [weak self] _ in
            guard let self = self else { return }
            
            Task { @MainActor in
                // æ£€æŸ¥æ˜¯å¦é•¿æ—¶é—´æ²¡æœ‰è¯†åˆ«ç»“æœ
                if let lastTime = self.lastTranscriptTime {
                    let timeSinceLastTranscript = Date().timeIntervalSince(lastTime)
                    if timeSinceLastTranscript > 10 {
                        if self.isDetectingAudio {
                            self.statusMessage = "ğŸ”Š æ£€æµ‹åˆ°å£°éŸ³ä½†æ— æ³•è¯†åˆ«ï¼Œè¯·è¯´æ¸…æ¥šä¸€ç‚¹"
                        } else {
                            self.statusMessage = "ğŸ¤” æ²¡æœ‰æ£€æµ‹åˆ°å£°éŸ³ï¼Œè¯·é è¿‘éº¦å…‹é£è¯´è¯"
                        }
                    }
                } else if let connectionTime = self.deepgramConnectionTime {
                    let timeSinceConnection = Date().timeIntervalSince(connectionTime)
                    if timeSinceConnection > 8 {
                        if self.isDetectingAudio {
                            self.statusMessage = "ğŸ”Š æ£€æµ‹åˆ°å£°éŸ³ä½†æ— æ³•è¯†åˆ«ï¼Œè¯·è¯´æ¸…æ¥šä¸€ç‚¹"
                        } else {
                            self.statusMessage = "ğŸ¤” æ²¡æœ‰æ£€æµ‹åˆ°å£°éŸ³ï¼Œè¯·é è¿‘éº¦å…‹é£è¯´è¯"
                        }
                    }
                }
            }
        }
    }
    
    private func resetNoAudioDetectionTimer() {
        // é‡æ–°å¯åŠ¨è®¡æ—¶å™¨
        startNoAudioDetectionTimer()
    }
    
    private func stopNoAudioDetectionTimer() {
        noAudioTimer?.invalidate()
        noAudioTimer = nil
    }
    
    // MARK: - éŸ³é¢‘å¤„ç†

    private func convertAndSendAudio(
        buffer: AVAudioPCMBuffer,
        converter: AVAudioConverter,
        targetFormat: AVAudioFormat
    ) {
        // åˆ›å»ºè¾“å‡ºç¼“å†²åŒº
        let capacity = AVAudioFrameCount(
            Double(buffer.frameLength) * targetFormat.sampleRate / buffer.format.sampleRate
        )
        guard
            let convertedBuffer = AVAudioPCMBuffer(
                pcmFormat: targetFormat,
                frameCapacity: capacity
            )
        else {
            return
        }

        var error: NSError?
        let inputBlock: AVAudioConverterInputBlock = { _, outStatus in
            outStatus.pointee = .haveData
            return buffer
        }

        converter.convert(to: convertedBuffer, error: &error, withInputFrom: inputBlock)

        if let error = error {
            Logger.error("éŸ³é¢‘è½¬æ¢å¤±è´¥: \(error)")
            return
        }

        // è½¬æ¢ä¸º Data
        guard let audioData = bufferToData(convertedBuffer) else {
            return
        }

        // å‘é€éŸ³é¢‘æ•°æ®
        Task {
            await sendAudioData(audioData)
        }
    }

    private func bufferToData(_ buffer: AVAudioPCMBuffer) -> Data? {
        guard let channelData = buffer.int16ChannelData else {
            return nil
        }

        let channelDataPointer = channelData.pointee
        let dataSize = Int(buffer.frameLength) * MemoryLayout<Int16>.size

        return Data(bytes: channelDataPointer, count: dataSize)
    }

    private func sendAudioData(_ data: Data) async {
        let message = URLSessionWebSocketTask.Message.data(data)

        do {
            try await webSocketTask?.send(message)
        } catch {
            // å¿½ç•¥å‘é€é”™è¯¯ï¼Œé¿å…æ—¥å¿—åˆ·å±
        }
    }

    // MARK: - å¿ƒè·³

    func startHeartbeat() {
        Timer.scheduledTimer(withTimeInterval: 30, repeats: true) { [weak self] _ in
            guard let self = self, self.isConnected else { return }

            Task {
                await self.sendMessage(["type": "ping"])
            }
        }
    }

    // MARK: - æ–­çº¿é‡è¿

    @MainActor
    private func startAutoReconnect() {
        // å¦‚æœä¸å…è®¸è‡ªåŠ¨é‡è¿ï¼Œç›´æ¥è¿”å›
        guard shouldAutoReconnect else { return }

        reconnectAttempts += 1

        // è®¡ç®—é‡è¿å»¶è¿Ÿï¼ˆæŒ‡æ•°é€€é¿ï¼Œæœ€å¤§ 30 ç§’ï¼‰
        let delay = min(Double(reconnectAttempts) * 2.0, 30.0)

        Logger.info("ğŸ”„ å°†åœ¨ \(delay) ç§’åé‡è¿ï¼ˆç¬¬ \(reconnectAttempts) æ¬¡ï¼‰")

        // å–æ¶ˆä¹‹å‰çš„é‡è¿è®¡æ—¶å™¨
        reconnectTimer?.invalidate()

        // åˆ›å»ºæ–°çš„é‡è¿è®¡æ—¶å™¨
        reconnectTimer = Timer.scheduledTimer(withTimeInterval: delay, repeats: false) { [weak self] _ in
            guard let self = self else { return }

            Task { @MainActor in
                Logger.info("ğŸ”„ å°è¯•é‡æ–°è¿æ¥...")
                await self.connect()

                // å¦‚æœè¿æ¥æˆåŠŸï¼Œé‡ç½®é‡è¿è®¡æ•°
                if self.isConnected {
                    self.reconnectAttempts = 0
                    Logger.info("âœ… é‡è¿æˆåŠŸ")
                }
            }
        }
    }

    // åœæ­¢è‡ªåŠ¨é‡è¿
    @MainActor
    func stopAutoReconnect() {
        shouldAutoReconnect = false
        reconnectTimer?.invalidate()
        reconnectTimer = nil
        Logger.info("â¹ï¸ å·²åœæ­¢è‡ªåŠ¨é‡è¿")
    }

    // å¯ç”¨è‡ªåŠ¨é‡è¿
    @MainActor
    func enableAutoReconnect() {
        shouldAutoReconnect = true
        Logger.info("â–¶ï¸ å·²å¯ç”¨è‡ªåŠ¨é‡è¿")
    }
}
